{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd7f0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 250000 cattle baseline records.\n",
      "üìÅ Preparing static datasets...\n",
      "‚¨ÜÔ∏è Uploading (chunked) ‚Üí kaggle/milk_yield.csv\n",
      "‚úîÔ∏è Chunked upload completed ‚Üí kaggle/milk_yield.csv\n",
      "‚¨ÜÔ∏è Uploading (chunked) ‚Üí kaggle/disease.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServiceResponseError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/storage/blob/_shared/policies.py:566\u001b[0m, in \u001b[0;36mStorageRetryPolicy.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 566\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_retry(response, retry_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;129;01mor\u001b[39;00m is_checksum_retry(response):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/core/pipeline/_base.py:98\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/core/pipeline/_base.py:98\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "    \u001b[0;31m[... skipping similar frames: _SansIOHTTPPolicyRunner.send at line 98 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/core/pipeline/_base.py:98\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/storage/blob/_shared/policies.py:309\u001b[0m, in \u001b[0;36mStorageResponseHook.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    305\u001b[0m response_callback \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m request\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mpop(\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_response_hook\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_callback\n\u001b[1;32m    307\u001b[0m )\n\u001b[0;32m--> 309\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[1;32m    311\u001b[0m will_retry \u001b[38;5;241m=\u001b[39m is_retry(response, request\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m is_checksum_retry(response)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/core/pipeline/_base.py:98\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/core/pipeline/_base.py:98\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/core/pipeline/_base.py:130\u001b[0m, in \u001b[0;36m_TransportRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    127\u001b[0m cleanup_kwargs_for_transport(request\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39moptions)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m PipelineResponse(\n\u001b[1;32m    129\u001b[0m     request\u001b[38;5;241m.\u001b[39mhttp_request,\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sender\u001b[38;5;241m.\u001b[39msend(request\u001b[38;5;241m.\u001b[39mhttp_request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39moptions),\n\u001b[1;32m    131\u001b[0m     context\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mcontext,\n\u001b[1;32m    132\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/storage/blob/_shared/base_client.py:360\u001b[0m, in \u001b[0;36mTransportWrapper.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend\u001b[39m(\u001b[38;5;28mself\u001b[39m, request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/storage/blob/_shared/base_client.py:360\u001b[0m, in \u001b[0;36mTransportWrapper.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend\u001b[39m(\u001b[38;5;28mself\u001b[39m, request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/core/pipeline/transport/_requests_basic.py:411\u001b[0m, in \u001b[0;36mRequestsTransport.send\u001b[0;34m(self, request, proxies, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error:\n\u001b[0;32m--> 411\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_rest(request):\n",
      "\u001b[0;31mServiceResponseError\u001b[0m: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 376\u001b[0m\n\u001b[1;32m    372\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(STREAM_INTERVAL_SEC)\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 376\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[4], line 362\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    359\u001b[0m container_client \u001b[38;5;241m=\u001b[39m get_blob_container()\n\u001b[1;32m    361\u001b[0m \u001b[38;5;66;03m# upload static + kaggle files\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m upload_static_datasets(container_client, base_df)\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# streaming forever\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[4], line 190\u001b[0m, in \u001b[0;36mupload_static_datasets\u001b[0;34m(container_client, base_df)\u001b[0m\n\u001b[1;32m    181\u001b[0m static_files \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkaggle/milk_yield.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m: MILK_FILE,\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkaggle/disease.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m: DISEASE_FILE,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatic/feed_type.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeed_type.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m }\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blob_name, local_path \u001b[38;5;129;01min\u001b[39;00m static_files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 190\u001b[0m     upload_big_file(container_client, blob_name, local_path)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úîÔ∏è ALL static + Kaggle datasets uploaded to Bronze!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 84\u001b[0m, in \u001b[0;36mupload_big_file\u001b[0;34m(container_client, blob_name, local_path)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Base64 block ID, fixed length\u001b[39;00m\n\u001b[1;32m     82\u001b[0m block_id \u001b[38;5;241m=\u001b[39m base64\u001b[38;5;241m.\u001b[39mb64encode(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m06d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mencode())\n\u001b[0;32m---> 84\u001b[0m blob_client\u001b[38;5;241m.\u001b[39mstage_block(\n\u001b[1;32m     85\u001b[0m     block_id\u001b[38;5;241m=\u001b[39mblock_id,\n\u001b[1;32m     86\u001b[0m     data\u001b[38;5;241m=\u001b[39mchunk\n\u001b[1;32m     87\u001b[0m )\n\u001b[1;32m     89\u001b[0m block_ids\u001b[38;5;241m.\u001b[39mappend(block_id)\n\u001b[1;32m     90\u001b[0m i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/core/tracing/decorator.py:119\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# If tracing is disabled globally and user didn't explicitly enable it, don't trace.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/storage/blob/_blob_client.py:2036\u001b[0m, in \u001b[0;36mBlobClient.stage_block\u001b[0;34m(self, block_id, data, length, **kwargs)\u001b[0m\n\u001b[1;32m   2030\u001b[0m options \u001b[38;5;241m=\u001b[39m _stage_block_options(\n\u001b[1;32m   2031\u001b[0m     block_id\u001b[38;5;241m=\u001b[39mblock_id,\n\u001b[1;32m   2032\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m   2033\u001b[0m     length\u001b[38;5;241m=\u001b[39mlength,\n\u001b[1;32m   2034\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2035\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2036\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Dict[\u001b[38;5;28mstr\u001b[39m, Any], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mblock_blob\u001b[38;5;241m.\u001b[39mstage_block(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions))\n\u001b[1;32m   2037\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HttpResponseError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m   2038\u001b[0m     process_storage_error(error)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/core/tracing/decorator.py:119\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# If tracing is disabled globally and user didn't explicitly enable it, don't trace.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/storage/blob/_generated/operations/_block_blob_operations.py:1269\u001b[0m, in \u001b[0;36mBlockBlobOperations.stage_block\u001b[0;34m(self, block_id, content_length, body, transactional_content_md5, transactional_content_crc64, timeout, request_id_parameter, structured_body_type, structured_content_length, lease_access_conditions, cpk_info, cpk_scope_info, **kwargs)\u001b[0m\n\u001b[1;32m   1266\u001b[0m _request\u001b[38;5;241m.\u001b[39murl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mformat_url(_request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m   1268\u001b[0m _stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1269\u001b[0m pipeline_response: PipelineResponse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_pipeline\u001b[38;5;241m.\u001b[39mrun(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m     _request, stream\u001b[38;5;241m=\u001b[39m_stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   1271\u001b[0m )\n\u001b[1;32m   1273\u001b[0m response \u001b[38;5;241m=\u001b[39m pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m201\u001b[39m]:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/core/pipeline/_base.py:242\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m pipeline_request: PipelineRequest[HTTPRequestType] \u001b[38;5;241m=\u001b[39m PipelineRequest(request, context)\n\u001b[1;32m    241\u001b[0m first_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl_policies[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl_policies \u001b[38;5;28;01melse\u001b[39;00m _TransportRunner(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport)\n\u001b[0;32m--> 242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m first_node\u001b[38;5;241m.\u001b[39msend(pipeline_request)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/core/pipeline/_base.py:98\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     96\u001b[0m _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_request, request)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_exception, request)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/core/pipeline/_base.py:98\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     96\u001b[0m _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_request, request)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_exception, request)\n",
      "    \u001b[0;31m[... skipping similar frames: _SansIOHTTPPolicyRunner.send at line 98 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/core/pipeline/_base.py:98\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     96\u001b[0m _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_request, request)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_exception, request)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/core/pipeline/policies/_redirect.py:205\u001b[0m, in \u001b[0;36mRedirectPolicy.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    203\u001b[0m original_domain \u001b[38;5;241m=\u001b[39m get_domain(request\u001b[38;5;241m.\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39murl) \u001b[38;5;28;01mif\u001b[39;00m redirect_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m retryable:\n\u001b[0;32m--> 205\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[1;32m    206\u001b[0m     redirect_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_redirect_location(response)\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m redirect_location \u001b[38;5;129;01mand\u001b[39;00m redirect_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/core/pipeline/_base.py:98\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     96\u001b[0m _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_request, request)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_exception, request)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/storage/blob/_shared/policies.py:584\u001b[0m, in \u001b[0;36mStorageRetryPolicy.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries_remaining:\n\u001b[1;32m    583\u001b[0m     retry_hook(retry_settings, request\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mhttp_request, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, error\u001b[38;5;241m=\u001b[39merr)\n\u001b[0;32m--> 584\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msleep(retry_settings, request\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39mtransport)\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/storage/blob/_shared/policies.py:491\u001b[0m, in \u001b[0;36mStorageRetryPolicy.sleep\u001b[0;34m(self, settings, transport)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backoff \u001b[38;5;129;01mor\u001b[39;00m backoff \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 491\u001b[0m transport\u001b[38;5;241m.\u001b[39msleep(backoff)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/azure/core/pipeline/transport/_base.py:177\u001b[0m, in \u001b[0;36mHttpTransport.sleep\u001b[0;34m(self, duration)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msleep\u001b[39m(\u001b[38;5;28mself\u001b[39m, duration: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sleep for the specified duration.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m    You should always ask the transport to sleep, and not call directly\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m    :param float duration: The number of seconds to sleep.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(duration)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# üîê CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "OPENWEATHER_KEY = \"OPENWEATHER_KEY\"\n",
    "\n",
    "AZ_ACCOUNT_NAME = \"herdtrackstorage1\"          \n",
    "AZ_ACCOUNT_KEY = \"AZ_ACCOUNT_KEY\"         \n",
    "AZ_CONTAINER_NAME = \"bronze\"\n",
    "\n",
    "# Kaggle datasets (local paths)\n",
    "MILK_FILE = \"./data/kaggle/global_cattle_milk_yield_prediction_dataset.csv\"\n",
    "DISEASE_FILE = \"./data/kaggle/global_cattle_disease_detection_dataset.csv\"\n",
    "\n",
    "REGION_TO_CITY = {\n",
    "    \"India\": \"Pune\",\n",
    "    \"USA\": \"Dallas\",\n",
    "    \"Kenya\": \"Nairobi\",\n",
    "    \"South Africa\": \"Johannesburg\",\n",
    "    \"Brazil\": \"Sao Paulo\",\n",
    "    \"UK\": \"London\"\n",
    "}\n",
    "DEFAULT_CITY = \"Dallas\"\n",
    "\n",
    "STREAM_INTERVAL_SEC = 120  # every 2 minutes\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ‚òÅÔ∏è CONNECT TO AZURE\n",
    "# ============================================================\n",
    "\n",
    "def get_blob_container():\n",
    "    conn_str = (\n",
    "        f\"DefaultEndpointsProtocol=https;AccountName={AZ_ACCOUNT_NAME};\"\n",
    "        f\"AccountKey={AZ_ACCOUNT_KEY};EndpointSuffix=core.windows.net\"\n",
    "    )\n",
    "    svc = BlobServiceClient.from_connection_string(conn_str)\n",
    "    return svc.get_container_client(AZ_CONTAINER_NAME)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# üîÑ CHUNKED UPLOAD (Fix for ConnectionResetError)\n",
    "# ============================================================\n",
    "\n",
    "import base64\n",
    "\n",
    "def upload_big_file(container_client, blob_name, local_path):\n",
    "\n",
    "    print(f\"‚¨ÜÔ∏è Uploading (chunked) ‚Üí {blob_name}\")\n",
    "\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "\n",
    "    # Delete existing blob if exists\n",
    "    try:\n",
    "        blob_client.delete_blob()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    block_ids = []\n",
    "    block_size = 256 * 1024  # 256 KB blocks\n",
    "\n",
    "    with open(local_path, \"rb\") as file:\n",
    "\n",
    "        i = 0\n",
    "        while True:\n",
    "            chunk = file.read(block_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "\n",
    "            # Base64 block ID, fixed length\n",
    "            block_id = base64.b64encode(f\"{i:06d}\".encode())\n",
    "\n",
    "            blob_client.stage_block(\n",
    "                block_id=block_id,\n",
    "                data=chunk\n",
    "            )\n",
    "\n",
    "            block_ids.append(block_id)\n",
    "            i += 1\n",
    "\n",
    "    # Commit block list\n",
    "    blob_client.commit_block_list(block_ids)\n",
    "\n",
    "    print(f\"‚úîÔ∏è Chunked upload completed ‚Üí {blob_name}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# üì¶ GENERATE STATIC TABLES\n",
    "# ============================================================\n",
    "\n",
    "def generate_realistic_static_tables(base_df):\n",
    "\n",
    "    cattle_ids = base_df[\"Cattle_ID\"].tolist()\n",
    "    regions = base_df[\"Region\"].tolist()\n",
    "\n",
    "    # Pregnancy Table\n",
    "    preg_rows = []\n",
    "    for cid in cattle_ids:\n",
    "        pregnant = random.random() < 0.30\n",
    "        if pregnant:\n",
    "            days = random.randint(1, 280)\n",
    "            due_date = datetime.now() + timedelta(days=(280 - days))\n",
    "            preg_rows.append([\n",
    "                cid, \"Pregnant\", days,\n",
    "                due_date.strftime(\"%Y-%m-%d\"),\n",
    "                (datetime.now() - timedelta(days=random.randint(10, 60))).strftime(\"%Y-%m-%d\"),\n",
    "                random.choice([\"Dr. Smith\", \"Dr. Patel\", \"Dr. John\", \"Dr. Anita\"])\n",
    "            ])\n",
    "        else:\n",
    "            preg_rows.append([\n",
    "                cid, \"Not Pregnant\", 0, \"\",\n",
    "                (datetime.now() - timedelta(days=random.randint(20, 120))).strftime(\"%Y-%m-%d\"),\n",
    "                random.choice([\"Dr. Smith\", \"Dr. Patel\", \"Dr. John\", \"Dr. Anita\"])\n",
    "            ])\n",
    "\n",
    "    preg_df = pd.DataFrame(\n",
    "        preg_rows,\n",
    "        columns=[\"Cattle_ID\", \"PregStatus\", \"DaysPregnant\", \"DueDate\", \"LastCheckupDate\", \"VetName\"]\n",
    "    )\n",
    "\n",
    "    # Sensor Metadata\n",
    "    sensor_rows = []\n",
    "    for cid in cattle_ids:\n",
    "        sensor_rows.append([\n",
    "            f\"SENSOR_{cid}\", cid,\n",
    "            random.choice([\"BioSensor\", \"EnvSensor\", \"FeedSensor\"]),\n",
    "            (datetime.now() - timedelta(days=random.randint(30, 300))).strftime(\"%Y-%m-%d\"),\n",
    "            random.randint(30, 100),\n",
    "            random.choice([\"v1.2.3\", \"v2.0.1\", \"v1.5.9\"])\n",
    "        ])\n",
    "\n",
    "    sensor_df = pd.DataFrame(\n",
    "        sensor_rows,\n",
    "        columns=[\"SensorID\", \"Cattle_ID\", \"SensorType\", \"InstallDate\", \"BatteryLevel\", \"FirmwareVersion\"]\n",
    "    )\n",
    "\n",
    "    # Feed Table\n",
    "    feed_rows = []\n",
    "    for cid, region in zip(cattle_ids, regions):\n",
    "        feed_rows.append([\n",
    "            cid,\n",
    "            random.choice([\"Grass\", \"Silage\", \"Corn\", \"Hay\", \"Concentrate\"]),\n",
    "            round(random.uniform(5, 12), 2),\n",
    "            random.choice([\"06:00\", \"18:00\"]),\n",
    "            round(random.uniform(2, 10), 2)\n",
    "        ])\n",
    "\n",
    "    feed_df = pd.DataFrame(\n",
    "        feed_rows,\n",
    "        columns=[\"Cattle_ID\", \"FeedType\", \"FeedQuantityKg\", \"FeedingTime\", \"FeedCostUSD\"]\n",
    "    )\n",
    "\n",
    "    return preg_df, sensor_df, feed_df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# üì§ UPLOAD STATIC + KAGGLE FILES\n",
    "# ============================================================\n",
    "\n",
    "def upload_static_datasets(container_client, base_df):\n",
    "\n",
    "    print(\"üìÅ Preparing static datasets...\")\n",
    "\n",
    "    preg_df, sensor_df, feed_df = generate_realistic_static_tables(base_df)\n",
    "\n",
    "    preg_df.to_csv(\"pregnancy_record.csv\", index=False)\n",
    "    sensor_df.to_csv(\"sensor_metadata.csv\", index=False)\n",
    "    feed_df.to_csv(\"feed_type.csv\", index=False)\n",
    "\n",
    "    static_files = {\n",
    "        \"kaggle/milk_yield.csv\": MILK_FILE,\n",
    "        \"kaggle/disease.csv\": DISEASE_FILE,\n",
    "        \"static/pregnancy_record.csv\": \"pregnancy_record.csv\",\n",
    "        \"static/sensor_metadata.csv\": \"sensor_metadata.csv\",\n",
    "        \"static/feed_type.csv\": \"feed_type.csv\"\n",
    "    }\n",
    "\n",
    "    for blob_name, local_path in static_files.items():\n",
    "        upload_big_file(container_client, blob_name, local_path)\n",
    "\n",
    "    print(\"‚úîÔ∏è ALL static + Kaggle datasets uploaded to Bronze!\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# üå¶Ô∏è WEATHER API\n",
    "# ============================================================\n",
    "\n",
    "def fetch_weather(city: str):\n",
    "    try:\n",
    "        r = requests.get(\n",
    "            f\"https://api.openweathermap.org/data/2.5/weather?q={city}&appid={OPENWEATHER_KEY}&units=metric\",\n",
    "            timeout=10\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        return {\n",
    "            \"city\": city,\n",
    "            \"temperature\": data[\"main\"][\"temp\"],\n",
    "            \"humidity\": data[\"main\"][\"humidity\"],\n",
    "            \"wind_speed\": data[\"wind\"][\"speed\"],\n",
    "            \"description\": data[\"weather\"][0][\"description\"]\n",
    "        }\n",
    "    except:\n",
    "        return {\n",
    "            \"city\": city,\n",
    "            \"temperature\": round(random.uniform(20, 30), 2),\n",
    "            \"humidity\": random.randint(45, 85),\n",
    "            \"wind_speed\": round(random.uniform(1, 7), 2),\n",
    "            \"description\": \"partly cloudy (simulated)\"\n",
    "        }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# üß† HEALTH SCORE LOGIC\n",
    "# ============================================================\n",
    "\n",
    "def compute_health_score(temp, milk, feed):\n",
    "    score = 100\n",
    "    if temp > 40: score -= 40\n",
    "    elif temp > 39.5: score -= 30\n",
    "    elif temp > 39: score -= 20\n",
    "\n",
    "    if milk < 8: score -= 25\n",
    "    elif milk < 10: score -= 15\n",
    "\n",
    "    if feed < 5: score -= 25\n",
    "    elif feed < 6: score -= 15\n",
    "\n",
    "    return max(0, min(100, int(round(score))))\n",
    "\n",
    "\n",
    "def classify_severity(score):\n",
    "    if score < 70: return \"Critical\"\n",
    "    if score < 90: return \"Medium\"\n",
    "    return \"Low\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# üìÑ LOAD BASE DATA\n",
    "# ============================================================\n",
    "\n",
    "def load_base_data():\n",
    "    milk_df = pd.read_csv(MILK_FILE)\n",
    "    disease_df = pd.read_csv(DISEASE_FILE)\n",
    "\n",
    "    base = pd.merge(\n",
    "        milk_df,\n",
    "        disease_df[[\"Cattle_ID\", \"Disease_Status\"]],\n",
    "        on=\"Cattle_ID\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    base = base[[\"Cattle_ID\", \"Region\", \"Milk_Yield_L\", \"Feed_Quantity_kg\", \"Disease_Status\"]]\n",
    "    base = base.drop_duplicates(subset=[\"Cattle_ID\"])\n",
    "\n",
    "    print(f\"‚úÖ Loaded {len(base)} cattle baseline records.\")\n",
    "    return base\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# üßÆ GENERATE ONE STREAM BATCH\n",
    "# ============================================================\n",
    "\n",
    "def generate_batch(base_df):\n",
    "    now = datetime.now(timezone.utc)\n",
    "\n",
    "    env_records = []\n",
    "    health_stream = []\n",
    "    alerts = []\n",
    "\n",
    "    # WEATHER per region\n",
    "    for region in base_df[\"Region\"].unique():\n",
    "        city = REGION_TO_CITY.get(region, DEFAULT_CITY)\n",
    "        w = fetch_weather(city)\n",
    "        env_records.append({\n",
    "            \"Region\": region,\n",
    "            \"City\": city,\n",
    "            \"RecordDateTime\": now.isoformat(),\n",
    "            \"Temperature\": w[\"temperature\"],\n",
    "            \"Humidity\": w[\"humidity\"],\n",
    "            \"WindSpeed\": w[\"wind_speed\"],\n",
    "            \"Description\": w[\"description\"]\n",
    "        })\n",
    "\n",
    "    # CATTLE health stream\n",
    "    for _, row in base_df.iterrows():\n",
    "\n",
    "        live_temp = round(random.uniform(37.5, 40.5), 2)\n",
    "        live_milk = round(row[\"Milk_Yield_L\"] + random.uniform(-2, 2), 2)\n",
    "        live_feed = round(row[\"Feed_Quantity_kg\"] + random.uniform(-1, 1), 2)\n",
    "\n",
    "        score = compute_health_score(live_temp, live_milk, live_feed)\n",
    "        severity = classify_severity(score)\n",
    "\n",
    "        health_stream.append({\n",
    "            \"Cattle_ID\": row[\"Cattle_ID\"],\n",
    "            \"Region\": row[\"Region\"],\n",
    "            \"LiveTemperature\": live_temp,\n",
    "            \"LiveMilkYield\": live_milk,\n",
    "            \"LiveFeedIntake\": live_feed,\n",
    "            \"HealthScore\": score,\n",
    "            \"Severity\": severity\n",
    "        })\n",
    "\n",
    "        alerts.append({\n",
    "            \"Cattle_ID\": row[\"Cattle_ID\"],\n",
    "            \"Region\": row[\"Region\"],\n",
    "            \"Severity\": severity,\n",
    "            \"Message\": f\"Cattle {row['Cattle_ID']} ‚Äì Temp:{live_temp}¬∞C, Milk:{live_milk}L, Feed:{live_feed}kg, Score:{score}\",\n",
    "            \"TriggerTime\": now.isoformat()\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"timestamp\": now.isoformat(),\n",
    "        \"env_records\": env_records,\n",
    "        \"health_stream\": health_stream,\n",
    "        \"alerts\": alerts\n",
    "    }, now\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# üßµ STREAM UPLOAD\n",
    "# ============================================================\n",
    "\n",
    "def upload_json_stream(container_client, batch, timestamp):\n",
    "    blob_name = f\"api_streams/herdtrack_stream_{timestamp}.json\"\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "\n",
    "    blob_client.upload_blob(\n",
    "        json.dumps(batch).encode(\"utf-8\"),\n",
    "        overwrite=True\n",
    "    )\n",
    "\n",
    "    print(f\"‚úîÔ∏è Stream uploaded ‚Üí {blob_name}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# üöÄ MAIN LOOP\n",
    "# ============================================================\n",
    "\n",
    "def main():\n",
    "\n",
    "    base_df = load_base_data()\n",
    "\n",
    "    # Keep 1000 cattle for streaming\n",
    "    base_df = base_df.sample(n=1000, random_state=42)\n",
    "\n",
    "    container_client = get_blob_container()\n",
    "\n",
    "    # upload static + kaggle files\n",
    "    upload_static_datasets(container_client, base_df)\n",
    "\n",
    "    # streaming forever\n",
    "    while True:\n",
    "        batch, now = generate_batch(base_df)\n",
    "        ts = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "        upload_json_stream(container_client, batch, ts)\n",
    "\n",
    "        print(f\"‚úÖ Batch {ts} ‚Üí {len(batch['alerts'])} alerts\")\n",
    "        time.sleep(STREAM_INTERVAL_SEC)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6326c6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
